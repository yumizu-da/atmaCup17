{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma:\n",
      "  model_path: unsloth/gemma-2-9b-it-bnb-4bit\n",
      "  metric: auc\n",
      "  max_length: 1024\n",
      "  fp16: true\n",
      "  learning_rate: 0.0001\n",
      "  epochs: 2\n",
      "  per_device_train_batch_size: 4\n",
      "  gradient_accumulation_steps: 16\n",
      "  per_device_eval_batch_size: 8\n",
      "  steps: 50\n",
      "  lr_scheduler_type: cosine\n",
      "  weight_decay: 0.01\n",
      "  optim: adamw_torch_fused\n",
      "  lora_r: 16\n",
      "  lora_alpha: 32\n",
      "  lora_dropout: 0.05\n",
      "  lora_bias: none\n",
      "exp_number: '017'\n",
      "run_name: base\n",
      "data:\n",
      "  data_root: ../../data\n",
      "  results_root: ../../results\n",
      "  train_path: ../../data/train.csv\n",
      "  cloth_path: ../../data/clothing_master.csv\n",
      "  test_path: ../../data/test.csv\n",
      "  sample_submission_path: ../../data/sample_submission.csv\n",
      "  results_dir: ../../results/017/base\n",
      "seed: 42\n",
      "n_splits: 4\n",
      "target: Recommended IND\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import safetensors\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from hydra import compose, initialize\n",
    "from jinja2 import Template\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.seed import seed_everything\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "with initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.exp_number = Path().resolve().name\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "pl.Config.set_fmt_str_lengths(100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM(gemma-2-9b-it)をQLoRAでファインチューニング\n",
    "- 2nd & 7th place solを参考に実装\n",
    "  - https://www.guruguru.science/competitions/24/discussions/4f2c7270-b67e-4e34-855a-3246f03cc278/\n",
    "  - https://www.guruguru.science/competitions/24/discussions/bdfb41e9-a1ef-40e8-b67d-742b5a4458a2/\n",
    "- Gemma2-9B(instruct tuning)のSequenceClassification\n",
    "- 4bit量子化されたモデル(unsloth/gemma-2-9b-it-bnb-4bit)をQLoRAでファインチューニング\n",
    "- エラー発生のため1foldのみの学習に留まる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(cfg.data.train_path, try_parse_dates=True).fill_null(\"none\")\n",
    "test_df = pl.read_csv(cfg.data.test_path, try_parse_dates=True).fill_null(\"none\")\n",
    "cloth_df = pl.read_csv(cfg.data.cloth_path, try_parse_dates=True)\n",
    "\n",
    "train_df = train_df.join(cloth_df, on=\"Clothing ID\", how=\"left\")\n",
    "test_df = test_df.join(cloth_df, on=\"Clothing ID\", how=\"left\")\n",
    "\n",
    "# labels列を作成\n",
    "train_df = train_df.with_columns(pl.col(cfg.target).cast(pl.Int8).alias(\"labels\"))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cfg.n_splits, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug設定\n",
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    train_df = train_df.head(100)\n",
    "    test_df = test_df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Clothing ID</th><th>Age</th><th>Title</th><th>Review Text</th><th>Rating</th><th>Recommended IND</th><th>Positive Feedback Count</th><th>Division Name</th><th>Department Name</th><th>Class Name</th><th>labels</th><th>prompt</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>i8</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>25</td><td>&quot;3-season skirt!&quot;</td><td>&quot;Adorable, well-made skirt! lined and very slimming. i had to size up b/c it runs a bit snug around t…</td><td>5</td><td>1</td><td>4</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>1</td><td>&quot;This reviewer&#x27;s Age is 25.\n",
       "The Clothing Type is Skirts.\n",
       "The Review Title: 3-season skirt!\n",
       "The Review…</td></tr><tr><td>0</td><td>39</td><td>&quot;Very cute&quot;</td><td>&quot;Love the asymmetrical hem. waist fit snugly as in perfectly. it ties in two spots with a hidden zipp…</td><td>5</td><td>1</td><td>0</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>1</td><td>&quot;This reviewer&#x27;s Age is 39.\n",
       "The Clothing Type is Skirts.\n",
       "The Review Title: Very cute\n",
       "The Review Text:…</td></tr><tr><td>0</td><td>42</td><td>&quot;Beautiful! fruns small for typical retailer sizing&quot;</td><td>&quot;I love this skirt! i wasn&#x27;t sure about the mix of the back pattern with the front but it works! it i…</td><td>5</td><td>1</td><td>5</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>1</td><td>&quot;This reviewer&#x27;s Age is 42.\n",
       "The Clothing Type is Skirts.\n",
       "The Review Title: Beautiful! fruns small for…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 12)\n",
       "┌─────────────┬─────┬─────────────┬────────────┬───┬────────────┬────────────┬────────┬────────────┐\n",
       "│ Clothing ID ┆ Age ┆ Title       ┆ Review     ┆ … ┆ Department ┆ Class Name ┆ labels ┆ prompt     │\n",
       "│ ---         ┆ --- ┆ ---         ┆ Text       ┆   ┆ Name       ┆ ---        ┆ ---    ┆ ---        │\n",
       "│ i64         ┆ i64 ┆ str         ┆ ---        ┆   ┆ ---        ┆ str        ┆ i8     ┆ str        │\n",
       "│             ┆     ┆             ┆ str        ┆   ┆ str        ┆            ┆        ┆            │\n",
       "╞═════════════╪═════╪═════════════╪════════════╪═══╪════════════╪════════════╪════════╪════════════╡\n",
       "│ 0           ┆ 25  ┆ 3-season    ┆ Adorable,  ┆ … ┆ Bottoms    ┆ Skirts     ┆ 1      ┆ This       │\n",
       "│             ┆     ┆ skirt!      ┆ well-made  ┆   ┆            ┆            ┆        ┆ reviewer's │\n",
       "│             ┆     ┆             ┆ skirt!     ┆   ┆            ┆            ┆        ┆ Age is 25. │\n",
       "│             ┆     ┆             ┆ lined and  ┆   ┆            ┆            ┆        ┆ The        │\n",
       "│             ┆     ┆             ┆ very       ┆   ┆            ┆            ┆        ┆ Clothing   │\n",
       "│             ┆     ┆             ┆ slimming.  ┆   ┆            ┆            ┆        ┆ Type is    │\n",
       "│             ┆     ┆             ┆ i had to   ┆   ┆            ┆            ┆        ┆ Skirts.    │\n",
       "│             ┆     ┆             ┆ size up    ┆   ┆            ┆            ┆        ┆ The Review │\n",
       "│             ┆     ┆             ┆ b/c it     ┆   ┆            ┆            ┆        ┆ Title:     │\n",
       "│             ┆     ┆             ┆ runs a bit ┆   ┆            ┆            ┆        ┆ 3-season   │\n",
       "│             ┆     ┆             ┆ snug       ┆   ┆            ┆            ┆        ┆ skirt!     │\n",
       "│             ┆     ┆             ┆ around t…  ┆   ┆            ┆            ┆        ┆ The        │\n",
       "│             ┆     ┆             ┆            ┆   ┆            ┆            ┆        ┆ Review…    │\n",
       "│ 0           ┆ 39  ┆ Very cute   ┆ Love the   ┆ … ┆ Bottoms    ┆ Skirts     ┆ 1      ┆ This       │\n",
       "│             ┆     ┆             ┆ asymmetric ┆   ┆            ┆            ┆        ┆ reviewer's │\n",
       "│             ┆     ┆             ┆ al hem.    ┆   ┆            ┆            ┆        ┆ Age is 39. │\n",
       "│             ┆     ┆             ┆ waist fit  ┆   ┆            ┆            ┆        ┆ The        │\n",
       "│             ┆     ┆             ┆ snugly as  ┆   ┆            ┆            ┆        ┆ Clothing   │\n",
       "│             ┆     ┆             ┆ in         ┆   ┆            ┆            ┆        ┆ Type is    │\n",
       "│             ┆     ┆             ┆ perfectly. ┆   ┆            ┆            ┆        ┆ Skirts.    │\n",
       "│             ┆     ┆             ┆ it ties in ┆   ┆            ┆            ┆        ┆ The Review │\n",
       "│             ┆     ┆             ┆ two spots  ┆   ┆            ┆            ┆        ┆ Title:     │\n",
       "│             ┆     ┆             ┆ with a     ┆   ┆            ┆            ┆        ┆ Very cute  │\n",
       "│             ┆     ┆             ┆ hidden     ┆   ┆            ┆            ┆        ┆ The Review │\n",
       "│             ┆     ┆             ┆ zipp…      ┆   ┆            ┆            ┆        ┆ Text:…     │\n",
       "│ 0           ┆ 42  ┆ Beautiful!  ┆ I love     ┆ … ┆ Bottoms    ┆ Skirts     ┆ 1      ┆ This       │\n",
       "│             ┆     ┆ fruns small ┆ this       ┆   ┆            ┆            ┆        ┆ reviewer's │\n",
       "│             ┆     ┆ for typical ┆ skirt! i   ┆   ┆            ┆            ┆        ┆ Age is 42. │\n",
       "│             ┆     ┆ retailer    ┆ wasn't     ┆   ┆            ┆            ┆        ┆ The        │\n",
       "│             ┆     ┆ sizing      ┆ sure about ┆   ┆            ┆            ┆        ┆ Clothing   │\n",
       "│             ┆     ┆             ┆ the mix of ┆   ┆            ┆            ┆        ┆ Type is    │\n",
       "│             ┆     ┆             ┆ the back   ┆   ┆            ┆            ┆        ┆ Skirts.    │\n",
       "│             ┆     ┆             ┆ pattern    ┆   ┆            ┆            ┆        ┆ The Review │\n",
       "│             ┆     ┆             ┆ with the   ┆   ┆            ┆            ┆        ┆ Title:     │\n",
       "│             ┆     ┆             ┆ front but  ┆   ┆            ┆            ┆        ┆ Beautiful! │\n",
       "│             ┆     ┆             ┆ it works!  ┆   ┆            ┆            ┆        ┆ fruns      │\n",
       "│             ┆     ┆             ┆ it i…      ┆   ┆            ┆            ┆        ┆ small for… │\n",
       "└─────────────┴─────┴─────────────┴────────────┴───┴────────────┴────────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# promptを作成\n",
    "prompt_template = Template(\"\"\"This reviewer's Age is {{ age }}.\n",
    "The Clothing Type is {{ class_name }}.\n",
    "The Review Title: {{ title }}\n",
    "The Review Text: {{ review_text }}\n",
    ">. Will the reviewer recommend this cloth?\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def make_prompt_column(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    prompts = []\n",
    "    for row in df.iter_rows(named=True):\n",
    "        prompts.append(make_prompt(row))\n",
    "\n",
    "    df = df.with_columns(pl.Series(prompts).alias(\"prompt\"))\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_prompt(row):\n",
    "    return prompt_template.render(\n",
    "        age=row[\"Age\"], class_name=row[\"Class Name\"], title=row[\"Title\"], review_text=row[\"Review Text\"]\n",
    "    )\n",
    "\n",
    "\n",
    "train_df = make_prompt_column(train_df)\n",
    "test_df = make_prompt_column(test_df)\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model and tokenizer\n",
    "def setup_model_and_tokenizer():\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.gemma.model_path)\n",
    "    tokenizer.add_eos_token = True\n",
    "    tokenizer.padding_side = \"right\"  # 文末に<eos>トークンを追加\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # <eos>をpad_tokenとして設定\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        r=cfg.gemma.lora_r,\n",
    "        lora_alpha=cfg.gemma.lora_alpha,\n",
    "        lora_dropout=cfg.gemma.lora_dropout,\n",
    "        bias=cfg.gemma.lora_bias,\n",
    "        inference_mode=False,\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # NOTE: device_mapを設定しないことで4foldの学習が可能になった\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg.gemma.model_path,\n",
    "        num_labels=2,\n",
    "    )\n",
    "    model.config.use_cache = False  # キャッシュを使用しない\n",
    "    model = prepare_model_for_kbit_training(model)  # 量子化したモデルをファインチューニング可能にする\n",
    "    model = get_peft_model(model, peft_config)  # モデルにLoRAを適用\n",
    "    # model.print_trainable_parameters()\n",
    "    return model, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize function\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"prompt\"], padding=\"max_length\", truncation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be137ba2b00543c29f852f72b3d2efca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d86ef62dd2c496aacc5e288854e4c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429ecc39420046bb803067faab5da9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 2:09:58, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.586500</td>\n",
       "      <td>0.280470</td>\n",
       "      <td>0.958950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.176984</td>\n",
       "      <td>0.972281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.158800</td>\n",
       "      <td>0.154028</td>\n",
       "      <td>0.976269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.143500</td>\n",
       "      <td>0.144071</td>\n",
       "      <td>0.977566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 AUC: 0.9775659437136971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713ef7f6b2fb4e33a85192b9181eed78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53808c900f241f986c544771a4c80dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794c2f51bbd14a12a8667f4edc1a040c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 2:09:18, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.269900</td>\n",
       "      <td>0.212704</td>\n",
       "      <td>0.960026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.244200</td>\n",
       "      <td>0.173933</td>\n",
       "      <td>0.973259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.156900</td>\n",
       "      <td>0.170154</td>\n",
       "      <td>0.970633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.151159</td>\n",
       "      <td>0.975682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 AUC: 0.9756824581197285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d125982abe4701858d37e1ef6c42a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9eb42258d448188fbfa0198373ac77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a51cfb92014804911ec2dd69eba483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 2:09:13, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.191252</td>\n",
       "      <td>0.962693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.177104</td>\n",
       "      <td>0.973359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.173700</td>\n",
       "      <td>0.193398</td>\n",
       "      <td>0.974605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.128500</td>\n",
       "      <td>0.155039</td>\n",
       "      <td>0.975767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 AUC: 0.9757669376693767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at unsloth/gemma-2-9b-it-bnb-4bit and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08982738c90a4c22ae23e5bf3f812216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437f8cf2d6cc4d498e58bfda5393d2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffd5060e69a4ee59851c9f2776601aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 2:09:20, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.212530</td>\n",
       "      <td>0.973205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.220500</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.968460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.158233</td>\n",
       "      <td>0.975437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.129700</td>\n",
       "      <td>0.152567</td>\n",
       "      <td>0.976259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 AUC: 0.9762590785907859\n",
      "Mean AUC score across all folds: 0.9763186045233971\n"
     ]
    }
   ],
   "source": [
    "# metricをAUCに変更\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = torch.softmax(torch.tensor(preds), dim=1).numpy()\n",
    "    score = roc_auc_score(labels, preds[:, 1])\n",
    "    return {\"auc\": score}\n",
    "\n",
    "\n",
    "# 実験結果格納用のディレクトリを作成\n",
    "cfg.run_name = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "Path(cfg.data.results_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "y_train = train_df[cfg.target].to_numpy()\n",
    "# oof = np.zeros(len(y_train))\n",
    "oof_auc = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y_train)):\n",
    "    # Setup model and tokenizer\n",
    "    model, tokenizer = setup_model_and_tokenizer()\n",
    "\n",
    "    # Setup dataset\n",
    "    ds_train = Dataset.from_pandas(train_df[train_idx][[\"prompt\", \"labels\"]].clone().to_pandas())\n",
    "    ds_val = Dataset.from_pandas(train_df[val_idx][[\"prompt\", \"labels\"]].clone().to_pandas())\n",
    "    ds_test = Dataset.from_pandas(test_df.select(\"prompt\").clone().to_pandas())\n",
    "\n",
    "    ds_train = ds_train.map(tokenize).remove_columns(\"prompt\")\n",
    "    ds_val = ds_val.map(tokenize).remove_columns(\"prompt\")\n",
    "    ds_test = ds_test.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    # Setup trainer\n",
    "    output_dir = os.path.join(cfg.data.results_dir, f\"fold{fold}\")\n",
    "\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=output_dir,  # 学習結果の出力ディレクトリ\n",
    "        fp16=cfg.gemma.fp16,  # 16ビット浮動小数点演算を使用するかどうか\n",
    "        learning_rate=cfg.gemma.learning_rate,  # 学習率\n",
    "        num_train_epochs=cfg.gemma.epochs,  # 学習エポック数\n",
    "        per_device_train_batch_size=cfg.gemma.per_device_train_batch_size,  # デバイスあたりの訓練バッチサイズ\n",
    "        per_device_eval_batch_size=cfg.gemma.per_device_eval_batch_size,  # デバイスあたりの評価バッチサイズ\n",
    "        gradient_accumulation_steps=cfg.gemma.gradient_accumulation_steps,  # 勾配蓄積ステップ数\n",
    "        gradient_checkpointing=True,  # 勾配チェックポイントを使用するかどうか\n",
    "        report_to=\"none\",  # レポート出力先（なし）\n",
    "        evaluation_strategy=\"steps\",  # 評価戦略（ステップごと）\n",
    "        do_eval=True,  # 評価を行うかどうか\n",
    "        eval_steps=cfg.gemma.steps,  # 評価を行うステップ間隔\n",
    "        save_total_limit=1,  # 保存するモデルの最大数\n",
    "        save_strategy=\"steps\",  # 保存戦略（ステップごと）\n",
    "        save_steps=cfg.gemma.steps,  # モデルを保存するステップ間隔\n",
    "        logging_steps=cfg.gemma.steps,  # ログを出力するステップ間隔\n",
    "        load_best_model_at_end=True,  # 学習終了時に最良のモデルをロードするかどうか\n",
    "        lr_scheduler_type=cfg.gemma.lr_scheduler_type,  # 学習率スケジューラーの種類\n",
    "        metric_for_best_model=cfg.gemma.metric,  # 最良モデルを判断するための評価指標\n",
    "        greater_is_better=True,  # 評価指標が大きいほど良いかどうか\n",
    "        warmup_ratio=0.1,  # ウォームアップの比率\n",
    "        weight_decay=cfg.gemma.weight_decay,  # 重み減衰\n",
    "        save_safetensors=True,  # SafeTensorsフォーマットで保存するかどうか\n",
    "        seed=cfg.seed,  # 乱数シード\n",
    "        data_seed=cfg.seed,  # データシャッフル用の乱数シード\n",
    "        optim=cfg.gemma.optim,  # 最適化アルゴリズム\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Perform inference on val and test datasets\n",
    "    pred_val = torch.softmax(torch.tensor(trainer.predict(ds_val).predictions), dim=1).numpy()[:, 1]\n",
    "    pred_test = torch.softmax(torch.tensor(trainer.predict(ds_test).predictions), dim=1).numpy()[:, 1]\n",
    "\n",
    "    # Save the model, predictions\n",
    "    final_output_dir = f\"{cfg.data.results_dir}/fold{fold}/final\"\n",
    "    trainer.save_model(final_output_dir)\n",
    "    np.save(f\"{final_output_dir}/val.npy\", pred_val)\n",
    "    np.save(f\"{final_output_dir}/test.npy\", pred_test)\n",
    "    # tokenizer.save_pretrained(final_output_dir)\n",
    "\n",
    "    # Calculate and log AUC score\n",
    "    roc_auc = roc_auc_score(y_train[val_idx], pred_val)\n",
    "    print(f\"Fold {fold} AUC: {roc_auc}\")\n",
    "    oof_auc.append(roc_auc)\n",
    "\n",
    "    # Clean up to free memory\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "print(f\"Mean AUC score across all folds: {np.mean(oof_auc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11155,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 各foldのtest.npyを読み込んで平均する\n",
    "pred_tests = []\n",
    "for fold in range(cfg.n_splits):\n",
    "    final_output_dir = f\"{cfg.data.results_dir}/fold{fold}/final\"\n",
    "    pred_test = np.load(f\"{final_output_dir}/test.npy\")\n",
    "    pred_tests.append(pred_test)\n",
    "\n",
    "pred_test = np.mean(pred_tests, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th></tr><tr><td>f32</td></tr></thead><tbody><tr><td>0.998476</td></tr><tr><td>0.604103</td></tr><tr><td>0.998511</td></tr><tr><td>0.171316</td></tr><tr><td>0.997938</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌──────────┐\n",
       "│ target   │\n",
       "│ ---      │\n",
       "│ f32      │\n",
       "╞══════════╡\n",
       "│ 0.998476 │\n",
       "│ 0.604103 │\n",
       "│ 0.998511 │\n",
       "│ 0.171316 │\n",
       "│ 0.997938 │\n",
       "└──────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出\n",
    "sub_df = pl.read_csv(cfg.data.sample_submission_path)\n",
    "sub_df = sub_df.with_columns(pl.Series(pred_test).alias(\"target\"))\n",
    "sub_df.write_csv(os.path.join(cfg.data.results_dir, f\"{cfg.run_name}_submission.csv\"))\n",
    "sub_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
