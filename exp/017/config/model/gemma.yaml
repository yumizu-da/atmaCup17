
model_path: unsloth/gemma-2-9b-it-bnb-4bit
metric: auc
max_length: 1024
fp16: true
learning_rate: 1.0e-04
epochs: 2
per_device_train_batch_size: 4
gradient_accumulation_steps: 16
per_device_eval_batch_size: 8
steps: 50
lr_scheduler_type: cosine
weight_decay: 0.01
optim: adamw_torch_fused

# lora
lora_r: 16
lora_alpha: 32
lora_dropout: 0.05
lora_bias: none
