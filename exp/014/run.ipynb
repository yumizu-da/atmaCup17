{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert:\n",
      "  params:\n",
      "    model_path: microsoft/deberta-v3-large\n",
      "    metric: auc\n",
      "    max_length: 192\n",
      "    fp16: true\n",
      "    learning_rate: 2.0e-05\n",
      "    epochs: 2\n",
      "    per_device_train_batch_size: 8\n",
      "    per_device_eval_batch_size: 8\n",
      "    steps: 100\n",
      "    lr_scheduler_type: cosine\n",
      "    weight_decay: 0.01\n",
      "exp_number: '014'\n",
      "run_name: base\n",
      "data:\n",
      "  data_root: ../../data\n",
      "  results_root: ../../results\n",
      "  train_path: ../../data/train.csv\n",
      "  cloth_path: ../../data/clothing_master.csv\n",
      "  test_path: ../../data/test.csv\n",
      "  sample_submission_path: ../../data/sample_submission.csv\n",
      "  results_dir: ../../results/014/base\n",
      "seed: 42\n",
      "n_splits: 5\n",
      "target: Recommended IND\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import safetensors\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from hydra import compose, initialize\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.seed import seed_everything\n",
    "from torch import nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PreTrainedModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "with initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.exp_number = Path().resolve().name\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Lossの実装\n",
    "- Ratingを回帰で予測する補助タスクを追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pl.read_csv(cfg.data.train_path, try_parse_dates=True)\n",
    "test_df = pl.read_csv(cfg.data.test_path, try_parse_dates=True)\n",
    "cloth_df = pl.read_csv(cfg.data.cloth_path, try_parse_dates=True)\n",
    "\n",
    "train_df = train_df.join(cloth_df, on=\"Clothing ID\", how=\"left\")\n",
    "test_df = test_df.join(cloth_df, on=\"Clothing ID\", how=\"left\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=cfg.n_splits, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Clothing ID</th><th>Age</th><th>Title</th><th>Review Text</th><th>Rating</th><th>Recommended IND</th><th>Positive Feedback Count</th><th>Division Name</th><th>Department Name</th><th>Class Name</th><th>prompt</th><th>labels</th><th>labels_aux</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i8</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>25</td><td>&quot;3-season skirt!&quot;</td><td>&quot;Adorable, well-made skirt! lin…</td><td>5</td><td>1</td><td>4</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>&quot;25-Year-Old&#x27;s Review of Skirts…</td><td>1</td><td>1.0</td></tr><tr><td>0</td><td>39</td><td>&quot;Very cute&quot;</td><td>&quot;Love the asymmetrical hem. wai…</td><td>5</td><td>1</td><td>0</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>&quot;39-Year-Old&#x27;s Review of Skirts…</td><td>1</td><td>1.0</td></tr><tr><td>0</td><td>42</td><td>&quot;Beautiful! fruns small for typ…</td><td>&quot;I love this skirt! i wasn&#x27;t su…</td><td>5</td><td>1</td><td>5</td><td>&quot;General&quot;</td><td>&quot;Bottoms&quot;</td><td>&quot;Skirts&quot;</td><td>&quot;42-Year-Old&#x27;s Review of Skirts…</td><td>1</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 13)\n",
       "┌─────────────┬─────┬─────────────┬────────────┬───┬────────────┬────────────┬────────┬────────────┐\n",
       "│ Clothing ID ┆ Age ┆ Title       ┆ Review     ┆ … ┆ Class Name ┆ prompt     ┆ labels ┆ labels_aux │\n",
       "│ ---         ┆ --- ┆ ---         ┆ Text       ┆   ┆ ---        ┆ ---        ┆ ---    ┆ ---        │\n",
       "│ i64         ┆ i64 ┆ str         ┆ ---        ┆   ┆ str        ┆ str        ┆ i8     ┆ f32        │\n",
       "│             ┆     ┆             ┆ str        ┆   ┆            ┆            ┆        ┆            │\n",
       "╞═════════════╪═════╪═════════════╪════════════╪═══╪════════════╪════════════╪════════╪════════════╡\n",
       "│ 0           ┆ 25  ┆ 3-season    ┆ Adorable,  ┆ … ┆ Skirts     ┆ 25-Year-Ol ┆ 1      ┆ 1.0        │\n",
       "│             ┆     ┆ skirt!      ┆ well-made  ┆   ┆            ┆ d's Review ┆        ┆            │\n",
       "│             ┆     ┆             ┆ skirt!     ┆   ┆            ┆ of Skirts… ┆        ┆            │\n",
       "│             ┆     ┆             ┆ lin…       ┆   ┆            ┆            ┆        ┆            │\n",
       "│ 0           ┆ 39  ┆ Very cute   ┆ Love the   ┆ … ┆ Skirts     ┆ 39-Year-Ol ┆ 1      ┆ 1.0        │\n",
       "│             ┆     ┆             ┆ asymmetric ┆   ┆            ┆ d's Review ┆        ┆            │\n",
       "│             ┆     ┆             ┆ al hem.    ┆   ┆            ┆ of Skirts… ┆        ┆            │\n",
       "│             ┆     ┆             ┆ wai…       ┆   ┆            ┆            ┆        ┆            │\n",
       "│ 0           ┆ 42  ┆ Beautiful!  ┆ I love     ┆ … ┆ Skirts     ┆ 42-Year-Ol ┆ 1      ┆ 1.0        │\n",
       "│             ┆     ┆ fruns small ┆ this       ┆   ┆            ┆ d's Review ┆        ┆            │\n",
       "│             ┆     ┆ for typ…    ┆ skirt! i   ┆   ┆            ┆ of Skirts… ┆        ┆            │\n",
       "│             ┆     ┆             ┆ wasn't su… ┆   ┆            ┆            ┆        ┆            │\n",
       "└─────────────┴─────┴─────────────┴────────────┴───┴────────────┴────────────┴────────┴────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG = False\n",
    "\n",
    "if DEBUG:\n",
    "    train_df = train_df.head(100)\n",
    "\n",
    "\n",
    "def preprocess_text(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col(\"Age\").fill_null(\"none\"),\n",
    "                pl.lit(\"-Year-Old's Review of \"),\n",
    "                pl.col(\"Class Name\").fill_null(\"none\"),\n",
    "                pl.lit(\" [SEP] \"),\n",
    "                pl.lit(\"TITLE: \"),\n",
    "                pl.col(\"Title\").fill_null(\"none\"),\n",
    "                pl.lit(\" [SEP] \"),\n",
    "                pl.lit(\"Review Text: \"),\n",
    "                pl.col(\"Review Text\").fill_null(\"none\"),\n",
    "                pl.lit(\" [SEP] \"),\n",
    "                pl.lit(\"Positive Feedback Count: \"),\n",
    "                pl.col(\"Positive Feedback Count\").fill_null(\"none\"),\n",
    "            ]\n",
    "        ).alias(\"prompt\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = preprocess_text(train_df)\n",
    "test_df = preprocess_text(test_df)\n",
    "\n",
    "# labels, labels_aux(Ratingを-1~1の範囲で正規化したもの)列を作成\n",
    "train_df = train_df.with_columns(pl.col(cfg.target).cast(pl.Int8).alias(\"labels\"))\n",
    "train_df = train_df.with_columns(((pl.col(\"Rating\") - 1) / 2 - 1).cast(pl.Float32).alias(\"labels_aux\"))\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"25-Year-Old's Review of Skirts [SEP] TITLE: 3-season skirt! [SEP] Review Text: Adorable, well-made skirt! lined and very slimming. i had to size up b/c it runs a bit snug around the waist. however, it's worth it b/c this will match many long and short sleeve tops! [SEP] Positive Feedback Count: 4\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt例\n",
    "train_df[\"prompt\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg.bert.params.model_path)\n",
    "\n",
    "\n",
    "def tokenize(sample):\n",
    "    return tokenizer(sample[\"prompt\"], max_length=cfg.bert.params.max_length, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: 185\n",
      "test_df: 184\n"
     ]
    }
   ],
   "source": [
    "# token長を確認 --> max_length 192で大丈夫\n",
    "print(\n",
    "    f\"train_df: {train_df.select(pl.col('prompt').map_elements(lambda x: len(tokenizer(x)['input_ids']))).max().item()}\"\n",
    ")\n",
    "print(\n",
    "    f\"test_df: {test_df.select(pl.col('prompt').map_elements(lambda x: len(tokenizer(x)['input_ids']))).max().item()}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i.shape: torch.Size([8, 256])\n",
      "logits: tensor([[ 0.2374, -0.0033],\n",
      "        [-0.5588,  0.2937],\n",
      "        [ 0.2417, -0.0051],\n",
      "        [ 0.2429,  0.0496],\n",
      "        [ 0.0212, -0.0886],\n",
      "        [ 0.2426, -0.0090],\n",
      "        [ 0.2287, -0.0040],\n",
      "        [-0.1137,  0.3852]], grad_fn=<AddmmBackward0>)\n",
      "logits_aux: tensor([[-0.3604],\n",
      "        [ 0.5676],\n",
      "        [-0.3579],\n",
      "        [ 1.0151],\n",
      "        [ 1.8611],\n",
      "        [-0.3616],\n",
      "        [-0.3790],\n",
      "        [ 0.2673]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 補助タスクを追加したカスタムモデル\n",
    "class Atma17CustomModel(PreTrainedModel):\n",
    "    config_class = AutoConfig\n",
    "\n",
    "    def __init__(self, model_path: str) -> None:\n",
    "        model_config = self.config_class.from_pretrained(model_path)\n",
    "        model_config.num_labels = 2  # 2値分類だから2\n",
    "        model_config.output_hidden_states = True\n",
    "        super().__init__(config=model_config)\n",
    "        self.model_config = model_config\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_path, config=model_config)\n",
    "\n",
    "        # Rating for regression\n",
    "        self.aux_head = nn.Linear(self.model.config.hidden_size, 1)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        labels: torch.Tensor | None = None,\n",
    "        attention_mask: torch.Tensor | None = None,\n",
    "    ) -> SequenceClassifierOutput:\n",
    "        # 通常の2値分類の出力を取得\n",
    "        out = self.model(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n",
    "\n",
    "        # 最終層の[CLS]トークンの出力を取り出して回帰headへの入力に使用\n",
    "        aux_out = self.aux_head(out.hidden_states[-1][:, 0])\n",
    "\n",
    "        # 回帰の出力を追加して返す\n",
    "        output = SequenceClassifierOutput(\n",
    "            logits=out.logits,\n",
    "            hidden_states=None,\n",
    "            attentions=None,\n",
    "            loss=out.loss,\n",
    "        )\n",
    "        output[\"logits_aux\"] = aux_out\n",
    "        return output\n",
    "\n",
    "\n",
    "def _test_model() -> None:\n",
    "    m = Atma17CustomModel(model_path=\"microsoft/deberta-v3-large\")\n",
    "    i = torch.randint(0, 1000, (8, 256))\n",
    "    out = m(i, torch.randint(0, 2, (8,)))\n",
    "    print(f\"i.shape: {i.shape}\")\n",
    "    print(f\"logits: {out.logits}\")\n",
    "    print(f\"logits_aux: {out.logits_aux}\")\n",
    "\n",
    "\n",
    "# 出力テスト\n",
    "_test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AuxLossを計算するカスタムTrainerを作成\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_fn_aux = nn.MSELoss()  # Ratingを回帰で予測するのでMSELossを使う\n",
    "# loss_fn_aux = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        labels_aux = inputs.pop(\"labels_aux\")\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        aux_logits = outputs.get(\"logits_aux\")\n",
    "        loss = loss_fn(logits.view(-1, 2), labels.view(-1))\n",
    "        loss_aux = loss_fn_aux(aux_logits.view(-1), labels_aux.view(-1))\n",
    "\n",
    "        return (loss + loss_aux, outputs) if return_outputs else loss + loss_aux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac15d1ca265645d1a8c7958ce191cea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70feebaf6e444af896a44eba927b9e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 12:50, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>0.402061</td>\n",
       "      <td>0.959145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.311917</td>\n",
       "      <td>0.965127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.262152</td>\n",
       "      <td>0.972522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.260700</td>\n",
       "      <td>0.250337</td>\n",
       "      <td>0.972667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.245860</td>\n",
       "      <td>0.973091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194a39fe6367478fadb30563d3e1d054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7fe7a81d7b4d6dba5a3fbb34791231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 08:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.706600</td>\n",
       "      <td>0.290962</td>\n",
       "      <td>0.966160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.355700</td>\n",
       "      <td>0.266871</td>\n",
       "      <td>0.972968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.265292</td>\n",
       "      <td>0.972989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.239736</td>\n",
       "      <td>0.974183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.231400</td>\n",
       "      <td>0.237453</td>\n",
       "      <td>0.974486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96115e40ebaf4724b8efd460e65d0f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50837f72b31844e0897a16d244b6eed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 11:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.695900</td>\n",
       "      <td>0.420144</td>\n",
       "      <td>0.961301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.353800</td>\n",
       "      <td>0.290094</td>\n",
       "      <td>0.969629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.300554</td>\n",
       "      <td>0.972197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.244600</td>\n",
       "      <td>0.258885</td>\n",
       "      <td>0.973385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.239000</td>\n",
       "      <td>0.254120</td>\n",
       "      <td>0.974319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748d404cb9084d1d83084ba9026e494b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e28603caff45f9b5781e4b557220ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 09:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.694200</td>\n",
       "      <td>0.330430</td>\n",
       "      <td>0.960051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.312609</td>\n",
       "      <td>0.963386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.269200</td>\n",
       "      <td>0.349107</td>\n",
       "      <td>0.965517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.274709</td>\n",
       "      <td>0.966801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.240500</td>\n",
       "      <td>0.271924</td>\n",
       "      <td>0.967621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d663982184e4fb88239600c1c66259a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e688feeaef42fcba53b431f5793866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 10:09, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.468540</td>\n",
       "      <td>0.953283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.369900</td>\n",
       "      <td>0.330006</td>\n",
       "      <td>0.971345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.267997</td>\n",
       "      <td>0.970594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.244293</td>\n",
       "      <td>0.974162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.246427</td>\n",
       "      <td>0.974276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# metricをAUCに変更\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, all_labels = eval_pred\n",
    "    # predsとall_labelsはメインタスクと補助タスクの分のtupleになるので、メインタスクのみの予測値とラベルを取り出す\n",
    "    if isinstance(all_labels, tuple):\n",
    "        labels = all_labels[0]\n",
    "    else:\n",
    "        labels = all_labels\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    preds = torch.softmax(torch.tensor(preds), dim=1).numpy()\n",
    "    score = roc_auc_score(labels, preds[:, 1])\n",
    "    return {\"auc\": score}\n",
    "\n",
    "\n",
    "# 実験結果格納用のディレクトリを作成\n",
    "cfg.run_name = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "Path(cfg.data.results_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "y_train = train_df[cfg.target].to_numpy()\n",
    "oof = np.zeros(len(y_train))\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, y_train)):\n",
    "    ds_train = Dataset.from_pandas(train_df[train_idx][[\"prompt\", \"labels\", \"labels_aux\"]].clone().to_pandas())\n",
    "    ds_val = Dataset.from_pandas(train_df[val_idx][[\"prompt\", \"labels\", \"labels_aux\"]].clone().to_pandas())\n",
    "\n",
    "    # config = AutoConfig.from_pretrained(cfg.bert.params.model_path, num_labels=2)\n",
    "    model = Atma17CustomModel(cfg.bert.params.model_path)\n",
    "\n",
    "    ds_train = ds_train.map(tokenize).remove_columns(\"prompt\")\n",
    "    ds_val = ds_val.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    output_dir = os.path.join(cfg.data.results_dir, f\"fold{fold}\")\n",
    "\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=output_dir,  # 学習結果の出力ディレクトリ\n",
    "        fp16=cfg.bert.params.fp16,  # 16ビット浮動小数点演算を使用するかどうか\n",
    "        learning_rate=cfg.bert.params.learning_rate,  # 学習率\n",
    "        num_train_epochs=cfg.bert.params.epochs,  # 学習エポック数\n",
    "        per_device_train_batch_size=cfg.bert.params.per_device_train_batch_size,  # デバイスあたりの訓練バッチサイズ\n",
    "        per_device_eval_batch_size=cfg.bert.params.per_device_eval_batch_size,  # デバイスあたりの評価バッチサイズ\n",
    "        gradient_accumulation_steps=4,  # 勾配蓄積ステップ数\n",
    "        report_to=\"none\",  # レポート出力先（なし）\n",
    "        evaluation_strategy=\"steps\",  # 評価戦略（ステップごと）\n",
    "        do_eval=True,  # 評価を行うかどうか\n",
    "        eval_steps=cfg.bert.params.steps,  # 評価を行うステップ間隔\n",
    "        save_total_limit=1,  # 保存するモデルの最大数\n",
    "        save_strategy=\"steps\",  # 保存戦略（ステップごと）\n",
    "        save_steps=cfg.bert.params.steps,  # モデルを保存するステップ間隔\n",
    "        logging_steps=cfg.bert.params.steps,  # ログを出力するステップ間隔\n",
    "        load_best_model_at_end=True,  # 学習終了時に最良のモデルをロードするかどうか\n",
    "        lr_scheduler_type=cfg.bert.params.lr_scheduler_type,  # 学習率スケジューラーの種類\n",
    "        metric_for_best_model=cfg.bert.params.metric,  # 最良モデルを判断するための評価指標\n",
    "        greater_is_better=True,  # 評価指標が大きいほど良いかどうか\n",
    "        warmup_ratio=0.1,  # ウォームアップの比率\n",
    "        weight_decay=cfg.bert.params.weight_decay,  # 重み減衰\n",
    "        save_safetensors=True,  # SafeTensorsフォーマットで保存するかどうか\n",
    "        seed=cfg.seed,  # 乱数シード\n",
    "        data_seed=cfg.seed,  # データシャッフル用の乱数シード\n",
    "        label_names=[\"labels\", \"labels_aux\"],  # 入力するラベルの名前\n",
    "    )\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_val,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    final_output_dir = f\"{cfg.data.results_dir}/fold{fold}/final\"\n",
    "    trainer.save_model(final_output_dir)\n",
    "    tokenizer.save_pretrained(final_output_dir)\n",
    "\n",
    "    # predictionはlabelとRatingの予測値のtupleを返すので、labelの予測値のみを取り出す必要あり\n",
    "    pred = torch.softmax(torch.tensor(trainer.predict(ds_val).predictions[0]), dim=1).numpy()\n",
    "    oof[val_idx] = pred[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir='../../results/014/20240905_121127/fold0/checkpoint-500'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de1100e3f7f4b6298f4e08e42e4de5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir='../../results/014/20240905_121127/fold1/checkpoint-500'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ccd68aa87740e9bbde6fc0c8b97207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir='../../results/014/20240905_121127/fold2/checkpoint-500'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1654ce747b4c43fb8a5b5b9bc6053813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir='../../results/014/20240905_121127/fold3/checkpoint-500'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db3ae06f9d741b8ac55439222bb5b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_dir='../../results/014/20240905_121127/fold4/checkpoint-500'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30cf31db7e042d684fcd0002012a1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "for fold in range(cfg.n_splits):\n",
    "    # ベストステップのモデルを取得\n",
    "    fold_dir = f\"{cfg.data.results_dir}/fold{fold}\"\n",
    "    checkpoint_dirs = [d for d in os.listdir(fold_dir) if d.startswith(\"checkpoint-\")]\n",
    "    results_dir = os.path.join(fold_dir, checkpoint_dirs[0])\n",
    "    print(f\"{results_dir=}\")\n",
    "\n",
    "    # カスタムモデルを採用しているので重みをロードしてくる必要がある\n",
    "    model = Atma17CustomModel(cfg.bert.params.model_path)\n",
    "    msg = model.load_state_dict(safetensors.torch.load_file(results_dir + \"/model.safetensors\"))\n",
    "    print(msg)\n",
    "\n",
    "    ds_test = Dataset.from_pandas(test_df.select(\"prompt\").clone().to_pandas())\n",
    "    ds_test = ds_test.map(tokenize).remove_columns(\"prompt\")\n",
    "\n",
    "    test_args = TrainingArguments(\n",
    "        output_dir=cfg.data.results_dir,\n",
    "        per_device_eval_batch_size=cfg.bert.params.per_device_eval_batch_size,\n",
    "        do_predict=True,\n",
    "        dataloader_drop_last=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=test_args,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    predictions = torch.softmax(torch.tensor(trainer.predict(ds_test).predictions[0]), dim=1).numpy()\n",
    "    preds.append(predictions[:, 1])\n",
    "\n",
    "pred = np.mean(preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th></tr><tr><td>f32</td></tr></thead><tbody><tr><td>0.998292</td></tr><tr><td>0.385737</td></tr><tr><td>0.997597</td></tr><tr><td>0.106215</td></tr><tr><td>0.997363</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌──────────┐\n",
       "│ target   │\n",
       "│ ---      │\n",
       "│ f32      │\n",
       "╞══════════╡\n",
       "│ 0.998292 │\n",
       "│ 0.385737 │\n",
       "│ 0.997597 │\n",
       "│ 0.106215 │\n",
       "│ 0.997363 │\n",
       "└──────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提出\n",
    "sub_df = pl.read_csv(cfg.data.sample_submission_path)\n",
    "sub_df = sub_df.with_columns(pl.Series(pred).alias(\"target\"))\n",
    "sub_df.write_csv(os.path.join(cfg.data.results_dir, f\"{cfg.run_name}_submission.csv\"))\n",
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof\n",
    "# fig, ax = plt.subplots(figsize=(12, 5))\n",
    "# sns.histplot(y_train, bins=50)\n",
    "# sns.histplot(oof, bins=50)\n",
    "# plt.legend([\"true\", \"oof\"])\n",
    "# plt.show()\n",
    "# fig.savefig(f\"{cfg.data.results_dir}/oof_hist.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
