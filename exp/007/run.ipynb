{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb:\n",
      "  params:\n",
      "    objective: binary\n",
      "    metric: auc\n",
      "    verbose: -1\n",
      "    boosting_type: gbdt\n",
      "    learning_rate: 0.01\n",
      "    max_depth: 5\n",
      "    num_leaves: 31\n",
      "    min_data_in_leaf: 50\n",
      "    bagging_fraction: 0.8\n",
      "    bagging_freq: 1\n",
      "    feature_fraction: 0.8\n",
      "    lambda_l1: 0\n",
      "    lambda_l2: 1\n",
      "    seed: 42\n",
      "  early_stopping_rounds: 100\n",
      "  log_evaluation: 100\n",
      "  num_boost_round: 10000000\n",
      "bert:\n",
      "  params:\n",
      "    model_path: microsoft/deberta-v3-large\n",
      "    metric: auc\n",
      "    target_col_class_num: 2\n",
      "    max_length: 192\n",
      "    fp16: true\n",
      "    learning_rate: 2.0e-05\n",
      "    epochs: 2\n",
      "    per_device_train_batch_size: 8\n",
      "    per_device_eval_batch_size: 32\n",
      "    steps: 50\n",
      "    lr_scheduler_type: linear\n",
      "    weight_decay: 0.01\n",
      "exp_number: '007'\n",
      "run_name: base\n",
      "data:\n",
      "  data_root: ../../data\n",
      "  results_root: ../../results\n",
      "  train_path: ../../data/train.csv\n",
      "  clothing_path: ../../data/clothing_master.csv\n",
      "  test_path: ../../data/test.csv\n",
      "  sample_submission_path: ../../data/sample_submission.csv\n",
      "  results_dir: ../../results/007/base\n",
      "seed: 42\n",
      "n_splits: 5\n",
      "target: Recommended IND\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.seed import seed_everything\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "with initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.exp_number = Path().resolve().name\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgb:\n",
      "  params:\n",
      "    objective: binary\n",
      "    metric: auc\n",
      "    verbose: -1\n",
      "    boosting_type: gbdt\n",
      "    learning_rate: 0.01\n",
      "    max_depth: 5\n",
      "    num_leaves: 31\n",
      "    min_data_in_leaf: 50\n",
      "    bagging_fraction: 0.8\n",
      "    bagging_freq: 1\n",
      "    feature_fraction: 0.8\n",
      "    lambda_l1: 0\n",
      "    lambda_l2: 1\n",
      "    seed: 42\n",
      "  early_stopping_rounds: 100\n",
      "  log_evaluation: 100\n",
      "  num_boost_round: 10000000\n",
      "bert:\n",
      "  params:\n",
      "    model_path: microsoft/deberta-v3-large\n",
      "    metric: auc\n",
      "    target_col_class_num: 2\n",
      "    max_length: 192\n",
      "    fp16: true\n",
      "    learning_rate: 2.0e-05\n",
      "    epochs: 2\n",
      "    per_device_train_batch_size: 8\n",
      "    per_device_eval_batch_size: 32\n",
      "    steps: 50\n",
      "    lr_scheduler_type: linear\n",
      "    weight_decay: 0.01\n",
      "exp_number: '007'\n",
      "run_name: base\n",
      "data:\n",
      "  data_root: ../../data\n",
      "  results_root: ../../results\n",
      "  train_path: ../../data/train.csv\n",
      "  clothing_path: ../../data/clothing_master.csv\n",
      "  test_path: ../../data/test.csv\n",
      "  sample_submission_path: ../../data/sample_submission.csv\n",
      "  results_dir: ../../results/007/base\n",
      "seed: 42\n",
      "n_splits: 5\n",
      "target: Recommended IND\n",
      "\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.seed import seed_everything\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "with initialize(config_path=\"config\", version_base=None):\n",
    "    cfg = compose(config_name=\"config\")\n",
    "    cfg.exp_number = Path().resolve().name\n",
    "\n",
    "print(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "seed_everything(cfg.seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1       perfect\n",
      "2       perfect\n",
      "3       perfect\n",
      "6       perfect\n",
      "8       perfect\n",
      "         ...   \n",
      "9972    perfect\n",
      "9973    perfect\n",
      "9974    perfect\n",
      "9987    perfect\n",
      "9992    perfect\n",
      "Name: importance_word, Length: 2046, dtype: object\n",
      "10       perfect\n",
      "14       perfect\n",
      "15       perfect\n",
      "17       perfect\n",
      "35       perfect\n",
      "          ...   \n",
      "11139    perfect\n",
      "11140    perfect\n",
      "11143    perfect\n",
      "11151    perfect\n",
      "11152    perfect\n",
      "Name: importance_word, Length: 2231, dtype: object\n"
     ]
    }
   ],
   "source": [
    "debug = False\n",
    "\n",
    "train_df = pd.read_csv(cfg.data.train_path)\n",
    "clothing_df = pd.read_csv(cfg.data.clothing_path)\n",
    "test_df = pd.read_csv(cfg.data.test_path)\n",
    "\n",
    "if debug:\n",
    "    train_df = train_df.sample(500)\n",
    "\n",
    "def preprocess(df):\n",
    "    df['importance_word'] = 'none'\n",
    "    # titleとreview textを結合\n",
    "    df['Title'] = df['Title'].fillna('none')\n",
    "    df['Review Text'] = df['Review Text'].fillna('none')\n",
    "    df['Texts'] = df['Title'] + ' ' + df['Review Text']\n",
    "    df.loc[df['Texts'].str.contains('fabric', case=False), 'importance_word'] = 'fabric'\n",
    "    df.loc[df['Texts'].str.contains('jeans', case=False), 'importance_word'] = 'jeans'\n",
    "    df.loc[df['Texts'].str.contains('wear', case=False), 'importance_word'] = 'wear'\n",
    "    df.loc[df['Texts'].str.contains('soft', case=False), 'importance_word'] = 'soft'\n",
    "    df.loc[df['Texts'].str.contains('looked', case=False), 'importance_word'] = 'looked'\n",
    "    df.loc[df['Texts'].str.contains('way', case=False), 'importance_word'] = 'way'\n",
    "    df.loc[df['Texts'].str.contains('great', case=False), 'importance_word'] = 'great'\n",
    "    df.loc[df['Texts'].str.contains('love', case=False), 'importance_word'] = 'love'\n",
    "    df.loc[df['Texts'].str.contains('comfortable', case=False), 'importance_word'] = 'comfortable'\n",
    "    df.loc[df['Texts'].str.contains('perfect', case=False), 'importance_word'] = 'perfect'\n",
    "\n",
    "    print(df[df['Texts'].str.contains('perfect', case=False)]['importance_word'])\n",
    "    df = df.drop('Texts', axis=1)\n",
    "\n",
    "    # df[\"prompt\"] = \"I am \" + df[\"Age\"].map(str) + \" years old\" + \" [SEP] \" + \"this review has \" + df[\"Positive Feedback Count\"].map(str)+ \" positive feedback by user\" + \" [SEP] \" + \"TITLE: \" + df[\"Title\"].fillna(\"none\") + \" [SEP] \" + \"REVIEW: \" + df[\"Review Text\"].fillna(\"none\")\n",
    "    # df[\"prompt\"] = \"This review has \" + df[\"Positive Feedback Count\"].map(str)+ \" positive feedback by user\" + \" [SEP] \" + \"TITLE: \" + df[\"Title\"].fillna(\"none\") + \" [SEP] \" + \"REVIEW: \" + df[\"Review Text\"].fillna(\"none\")\n",
    "    df[\"prompt\"] =  \"The cloth id to be reviewed is \" + df[\"Clothing ID\"].map(str) + \" [SEP] \" + \"TITLE: \" + df[\"Title\"].fillna(\"none\") + \" [SEP] \" + \"REVIEW: \" + df[\"Review Text\"].fillna(\"none\")\n",
    "    return df\n",
    "\n",
    "train_df = preprocess(train_df)\n",
    "test_df = preprocess(test_df)\n",
    "train_df[\"labels\"] = train_df[cfg.target].astype(np.int8)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=cfg.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'labels', 'index'],\n",
      "    num_rows: 7999\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71902e34e1fe4b95b57facef6cffa030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fdb0ff9fc440f08d27af46a47dc27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 06:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.263507</td>\n",
       "      <td>0.931647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.227800</td>\n",
       "      <td>0.183931</td>\n",
       "      <td>0.961167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>0.185553</td>\n",
       "      <td>0.962690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.180314</td>\n",
       "      <td>0.963109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.235426</td>\n",
       "      <td>0.966885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.141100</td>\n",
       "      <td>0.209178</td>\n",
       "      <td>0.968747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.207735</td>\n",
       "      <td>0.969895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.181866</td>\n",
       "      <td>0.966925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.173064</td>\n",
       "      <td>0.968979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.113400</td>\n",
       "      <td>0.173439</td>\n",
       "      <td>0.968464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'labels', 'index'],\n",
      "    num_rows: 7999\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dc90fe88a14784ab6b0c28214360a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8607776f5d1c4150ad9c416d25112f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 05:40, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.242773</td>\n",
       "      <td>0.955521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.245600</td>\n",
       "      <td>0.200725</td>\n",
       "      <td>0.961695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.213500</td>\n",
       "      <td>0.200411</td>\n",
       "      <td>0.967768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.180400</td>\n",
       "      <td>0.191086</td>\n",
       "      <td>0.969350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.172321</td>\n",
       "      <td>0.970654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>0.194312</td>\n",
       "      <td>0.971231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.225534</td>\n",
       "      <td>0.970178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.138100</td>\n",
       "      <td>0.189404</td>\n",
       "      <td>0.972220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.196199</td>\n",
       "      <td>0.972593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>0.169727</td>\n",
       "      <td>0.973027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'labels', 'index'],\n",
      "    num_rows: 8000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1661cee5219b431e87311e088ac6f7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4683704be354d07920b612b3de85d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 05:36, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>0.321435</td>\n",
       "      <td>0.953781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.278738</td>\n",
       "      <td>0.936206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.202784</td>\n",
       "      <td>0.964671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.183300</td>\n",
       "      <td>0.209584</td>\n",
       "      <td>0.964491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.171496</td>\n",
       "      <td>0.973360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>0.193593</td>\n",
       "      <td>0.972303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.202721</td>\n",
       "      <td>0.973289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.153200</td>\n",
       "      <td>0.187302</td>\n",
       "      <td>0.971323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.156646</td>\n",
       "      <td>0.974203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.161434</td>\n",
       "      <td>0.974558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'labels', 'index'],\n",
      "    num_rows: 8001\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b296a86e95984286976465e428319f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed57df6a6e1f4dbb939d04a7b5c73c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 05:34, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.226114</td>\n",
       "      <td>0.940164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0.189045</td>\n",
       "      <td>0.965570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.196100</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>0.964059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.225900</td>\n",
       "      <td>0.178075</td>\n",
       "      <td>0.970061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.187100</td>\n",
       "      <td>0.166814</td>\n",
       "      <td>0.970523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.150500</td>\n",
       "      <td>0.198751</td>\n",
       "      <td>0.968401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.203892</td>\n",
       "      <td>0.968757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>0.188408</td>\n",
       "      <td>0.971414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.197155</td>\n",
       "      <td>0.971685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.146200</td>\n",
       "      <td>0.187877</td>\n",
       "      <td>0.972153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['prompt', 'labels', 'index'],\n",
      "    num_rows: 8001\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3956ec78db8a4c07ac9e1a7742a9ef5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8001 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1aeb2b4f20415bb93c0525d382d853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1999 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 05:37, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.252059</td>\n",
       "      <td>0.952603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.231116</td>\n",
       "      <td>0.920020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.295978</td>\n",
       "      <td>0.922851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.180602</td>\n",
       "      <td>0.968140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.186270</td>\n",
       "      <td>0.969209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.152600</td>\n",
       "      <td>0.191771</td>\n",
       "      <td>0.968247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.150300</td>\n",
       "      <td>0.191066</td>\n",
       "      <td>0.972523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.162200</td>\n",
       "      <td>0.185271</td>\n",
       "      <td>0.974587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.168800</td>\n",
       "      <td>0.178655</td>\n",
       "      <td>0.973987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.175168</td>\n",
       "      <td>0.974600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = torch.softmax(torch.tensor(preds), dim = 1).numpy()\n",
    "    score = roc_auc_score(labels, preds[:, 1])\n",
    "    return {'auc': score}\n",
    "\n",
    "# 実験結果格納用のディレクトリを作成\n",
    "cfg.run_name = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "Path(cfg.data.results_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "y_train = train_df[cfg.target]\n",
    "oof = np.zeros(len(train_df))\n",
    "\n",
    "# train_df[cfg.target]が0か1かでデータを分割する\n",
    "train_df['fold'] = 99\n",
    "# 元のindexを保持するためにindexを新たに作成\n",
    "train_df['index'] = train_df.index\n",
    "train_df_0 = train_df[train_df[cfg.target] == 0].reset_index(drop=True)\n",
    "train_df_1 = train_df[train_df[cfg.target] == 1].reset_index(drop=True)\n",
    "\n",
    "# それぞれのデータフレームで、Clothing IDをtargetにstratified kfoldし、それぞれのfoldを結合する\n",
    "for fold, (_, val_id) in enumerate(kf.split(train_df_0, train_df_0['importance_word'])):\n",
    "    train_df_0.loc[val_id, 'fold'] = fold\n",
    "for fold, (_, val_id) in enumerate(kf.split(train_df_1, train_df_1['importance_word'])):\n",
    "    train_df_1.loc[val_id, 'fold'] = fold\n",
    "\n",
    "train_df = pd.concat([train_df_0, train_df_1]).set_index('index').sort_index()\n",
    "\n",
    "# それぞれのfoldで学習を行う\n",
    "for fold in range(5):\n",
    "\n",
    "    valid_index = train_df[train_df['fold'] == fold].index\n",
    "\n",
    "    ds_train = Dataset.from_pandas(train_df[train_df['fold'] != fold][['prompt', 'labels']].copy())\n",
    "    ds_eval = Dataset.from_pandas(train_df[train_df['fold'] == fold][['prompt', 'labels']].copy())\n",
    "\n",
    "    # ds_trainの中身を確認\n",
    "    print(ds_train)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.bert.params.model_path)\n",
    "    config = AutoConfig.from_pretrained(cfg.bert.params.model_path)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(cfg.bert.params.model_path, config=config)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        return tokenizer(sample['prompt'], max_length=cfg.bert.params.max_length, truncation=True)\n",
    "\n",
    "    ds_train = ds_train.map(tokenize).remove_columns(['prompt', 'index'])\n",
    "    ds_eval = ds_eval.map(tokenize).remove_columns(['prompt', 'index'])\n",
    "\n",
    "    output_dir = f\"{cfg.data.results_dir}/fold{fold}\"\n",
    "\n",
    "    train_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        fp16=cfg.bert.params.fp16,\n",
    "        learning_rate=cfg.bert.params.learning_rate,\n",
    "        num_train_epochs=cfg.bert.params.epochs,\n",
    "        per_device_train_batch_size=cfg.bert.params.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=cfg.bert.params.per_device_eval_batch_size,\n",
    "        gradient_accumulation_steps=4,\n",
    "        report_to=\"none\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        eval_steps=cfg.bert.params.steps,\n",
    "        save_total_limit=1,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=cfg.bert.params.steps,\n",
    "        logging_steps=cfg.bert.params.steps,\n",
    "        load_best_model_at_end=True,\n",
    "        lr_scheduler_type=cfg.bert.params.lr_scheduler_type,\n",
    "        metric_for_best_model=cfg.bert.params.metric,\n",
    "        greater_is_better=True,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=cfg.bert.params.weight_decay,\n",
    "        save_safetensors=True,\n",
    "        seed=cfg.seed,\n",
    "        data_seed=cfg.seed,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=train_args,\n",
    "        train_dataset=ds_train,\n",
    "        eval_dataset=ds_eval,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    final_output_dir = f\"{cfg.data.results_dir}/fold{fold}/final\"\n",
    "    trainer.save_model(final_output_dir)\n",
    "    tokenizer.save_pretrained(final_output_dir)\n",
    "\n",
    "    pred = torch.softmax(torch.tensor(trainer.predict(ds_eval).predictions), dim=1).numpy()\n",
    "    oof[valid_index] = pred[:, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "oof_df = pd.DataFrame({\"oof\": oof})\n",
    "oof_df.to_csv(f\"{cfg.data.results_dir}/oof.csv\", index=False)\n",
    "\n",
    "best_score = roc_auc_score(y_train, oof)\n",
    "with open(f\"{cfg.data.results_dir}/log.txt\", \"w\") as log_file:\n",
    "    log_file.write(\"====== CV Score ======\\n\")\n",
    "    log_file.write(f\"best_score: {best_score}\\n\")\n",
    "    log_file.write(\"\\n====== params ======\\n\")\n",
    "    log_file.write(OmegaConf.to_yaml(cfg, resolve=True))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "sns.histplot(y_train, bins=50)\n",
    "sns.histplot(oof, bins=50)\n",
    "plt.legend([\"true\", \"oof\"])\n",
    "plt.show()\n",
    "fig.savefig(f\"{cfg.data.results_dir}/oof_hist.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUbmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991abc57165843a496a71c95e41225b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896095980ee34b7fa35b6319bb33d88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b59d0efae55479aaefe566edcab586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db666d4e98534e1e9c71c1acafbeb642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0fc4e9e02443a3aa87870cfc81c577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0  0.998566\n",
       "1  0.286377\n",
       "2  0.998584\n",
       "3  0.097078\n",
       "4  0.997598"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(sample):\n",
    "    return tokenizer(sample['prompt'], max_length=cfg.bert.params.max_length, truncation=True)\n",
    "\n",
    "preds = []\n",
    "for i in range(5):\n",
    "    results_dir = f\"{cfg.data.results_dir}/fold{i}/final\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(results_dir)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(results_dir)\n",
    "\n",
    "    ds_test = Dataset.from_pandas(test_df[['prompt']].copy())\n",
    "    ds_test = ds_test.map(tokenize).remove_columns(['prompt'])\n",
    "\n",
    "    test_args = TrainingArguments(\n",
    "        output_dir=cfg.data.results_dir,\n",
    "        per_device_eval_batch_size=cfg.bert.params.per_device_eval_batch_size,\n",
    "        do_predict=True,\n",
    "        dataloader_drop_last=False,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=test_args,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    predictions = torch.softmax(torch.tensor(trainer.predict(ds_test).predictions), dim=1).numpy()\n",
    "    preds.append(predictions[:, 1])\n",
    "\n",
    "pred = np.mean(preds, axis=0)\n",
    "\n",
    "# 提出用ファイル作成\n",
    "sub_df = pd.read_csv(cfg.data.sample_submission_path)\n",
    "sub_df[\"target\"] = pred\n",
    "sub_df.to_csv(f\"{cfg.data.results_dir}/{cfg.run_name}_submission.csv\", index=False)\n",
    "sub_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
